{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "43531c3c",
   "metadata": {},
   "source": [
    "# Short-Term Investment Strategies with Deep Q-Network (DQN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "605ef836",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "\n",
    "> [1. Introduction](#Introduction--1)\n",
    "\n",
    "> [2. Current SOTA](#SOTA--2)\n",
    "\n",
    "> [3. The *environment* and *reward* signal](#env_and_reward--3)\n",
    "\n",
    "> [4. Development and Implementation](#dev_and_impl--4)\n",
    ">> - [4.1. Instatiation of the trading environment](#Instantiation--4-1)\n",
    ">> - [4.2. Fundamental hyperparameters to tweak](#hyperparameters--4-2)\n",
    ">> - [4.3. Observation Space: Relative Price Variations](#observation_space--4-3)\n",
    "\n",
    "> [5. Deep Q-Network Acrhitecture](#DQN_architecture--5)\n",
    ">> - [5.1. Experience Replay Buffer](#E_R_B--5-1)\n",
    ">> - [5.2. Neural Network Architecture](#NN_Architecture--5-2)\n",
    ">> - [5.3. Exploration Vs Exploitation](#Exploration_vs_Exploitation--5-3)\n",
    ">> - [5.4. Policy Evaluation](#Policy_Evaluation--5-4)\n",
    "\n",
    "> [6. Putting things together, Deep Q-Network algorithm](#Putting_things_together--6)\n",
    ">> - [6.1. Compare *DQN* to *random_pi*](#compare--6-1)\n",
    "\n",
    "> [7. What our Agent is Capable of](#capabilities--7)\n",
    "\n",
    "> [8. Conclusions, Limitations and Future Improvements](#Conclusions--8)\n",
    "\n",
    "> [9. Appendix](#Appendix--9)\n",
    ">> - [9.A. On the formulation of the Markov Decision Process in financial trading](#Appendix--9-A)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e2c24f4",
   "metadata": {},
   "source": [
    "## 1. Introduction  <a name = \"Introduction--1\"></a>\n",
    "\n",
    "The goal of this Jupyter Notebook is to explore the application of **Deep Reinforcement Learning**, and in particular the **Deep Q-Network (DQN)** algorithm, in the domain of financial investments, with a focus on **short-term investment strategies**.\n",
    "\n",
    "The investment landscape can be broadly divided into two main categories.  \n",
    "1. **Long-term investments**, typically rely on macroeconomic factors, political events, corporate decisions, and geopolitical dynamics, and are often analyzed through [fundamental analysis](https://en.wikipedia.org/wiki/Fundamental_analysis).  \n",
    "2. **short-term investments**, which include trading activities, operate over much shorter time horizons and are commonly studied using mathematical and statistical models.\n",
    "\n",
    "Traditional approaches in quantitative finance for short-term price modeling include tools such as **ARIMA models**, **Geometric Brownian Motion (GBM)**, and model-based frameworks like the **Black–Scholes model**, (if you are interested, see my [arXiv paper here](https://arxiv.org/pdf/2510.27277)). While powerful, these methods rely on strong assumptions about market dynamics.\n",
    "\n",
    "In this notebook, we adopt a different perspective by leveraging **Artificial Intelligence**, in particular **Reinforcement Learning (RL)**.\\\n",
    "Instead of explicitly modeling price dynamics, we allow an agent to **learn a trading policy directly from interactions with the market environment**, guided by a reward signal.\n",
    "\n",
    "A crucial step in this process is the design of a suitable **trading environment**. The environment must comply with the standard **Gymnasium** interface and provide:\n",
    "- A well-defined **action space** (e.g.: buy, sell, hold);\n",
    "- An **observation space** representing the market state;\n",
    "- Proper **termination and truncation conditions**;\n",
    "- A **reward function** that encodes the trading objective.\n",
    "\n",
    "Once the environment is defined, it is coupled with a **DQN agent**, which is trained through repeated interactions with the market.\\\n",
    "Finally, the trained agent's policy is evaluated by analyzing the accumulated rewards compared to a random policy, in order to assess the effectiveness and robustness of the learned trading strategy.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ef29ad9",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center;\">\n",
    "    <img src=\"trading_bot.JPG\" alt=\"trading bot image\" width=\"66%\"/>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79e799d6",
   "metadata": {},
   "source": [
    "## 2. Current SOTA <a name=\"SOTA--2\"></a>\n",
    "\n",
    "It is important to point out that [Gymnasium](https://gymnasium.farama.org/), which is a standardized API for RL ready-to-use environments, currently does not have any predefined trading environment, all we have are some projects carried out 'unofficially', that often lack of correctness and rigorous methoods or documentation.\n",
    "\n",
    "* [gym-anytrading](https://github.com/AminHP/gym-anytrading), repository GitHub for a possible trading environment.\n",
    "* [tensortrade](https://github.com/tensortrade-org/tensortrade), Python library for reinforcement learning applied in trading.\n",
    "* [q-trader](https://github.com/edwardhdlu/q-trader?tab=readme-ov-file), application of reinforcement learning in the stock market.\n",
    "\n",
    "These three, seem to be the most relevant sources we can find on the web, but as already noted, they lack of proper documentation and rigorous method.\n",
    "\n",
    "In any case, the application of RL techniques in investments is already quite widespread as mentioned by this article [link](https://medium.com/ibm-data-ai/reinforcement-learning-the-business-use-case-part-2-c175740999), where prestigious firms suchs IBM or J.P. Morgan, already apply some of these techniques."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20569071",
   "metadata": {},
   "source": [
    "## 3. The *environment* and  *reward* signal <a name=\"env_and_reward--3\"></a>\n",
    "\n",
    "Given the current SOTA available and having understood the main dynamics of a market stock, the first thing to do, is the design of our own environment.\\\n",
    "The Python script `tradingenv` contains our environment class, `TradingEnv()`. It could be used as a starting point for many other RL projects, since it contains a proper methodology with many comments that enhance the understanding of the development.\n",
    "\n",
    "TradingEnv has all the methods that make it compliant to the Gym environments. But the most relevant thing to understand is how the **reward** signal is defined, as shown here:\n",
    "\n",
    "$ reward = (cash_{t+1} + shares_{t+1} \\cdot p_{t+1}) - (cash_{t} + shares_{t} \\cdot p_{t}) $\n",
    "\n",
    "where:\n",
    "* $reward$, indicates the reward obtained after taking the action at time-step $t$\n",
    "* $cash_{t}$, indicates the amount of cash held at time step $t$\n",
    "* $share_{t}$, indicates the amount of shares held at time step $t$\n",
    "* $p_{t}$, indicates the price of a single share at time step $t$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48030a4d",
   "metadata": {},
   "source": [
    "## 4. Development and Implementation <a name=\"dev_and_impl--4\"></a>\n",
    "\n",
    "import of all the necessary libraries, environment, numerical computations, NN and rendering...\\\n",
    "Make sure to have the script `tradingenv`!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "48194505",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import of our defined environment\n",
    "#YOU MUST ALSO HAVE THE SCRIPT \"tradingenv.py\"\n",
    "from tradingenv import TradingEnv\n",
    "\n",
    "import torch #for Neural Networks\n",
    "import numpy as np #for numerical operations\n",
    "import random #for random number generation\n",
    "import matplotlib.pyplot as plt #for plotting the results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fb060ce",
   "metadata": {},
   "source": [
    "Practical example of how to use the library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78ac408d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" example of how to use the described environment\n",
    "env = TradingEnv(ticker=\"AAPL\", granularity=\"1d\", sliding_window=7, start_date=\"2020-01-01\", end_date=\"2021-01-01\", initial_cash=10000, initial_share=5)\n",
    "obs, info = env.reset()\n",
    "action = env.action_space.sample()  # es. 0=buy,1=hold,2=sell\n",
    "obs, reward, done, truncated, info = env.step(action)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b2e04a9",
   "metadata": {},
   "source": [
    "### 4.1 Instantiation of the trading environment <a name=\"Instantiation--4-1\"></a>\n",
    "\n",
    "Note, you can select the granularity as the interval parameter of the `yfinance` [library](https://ranaroussi.github.io/yfinance/), representing the time scale over which you want to operate.\\\n",
    "Supported time scale: \n",
    "\n",
    "#### Short-time trading (intraday)\n",
    "\n",
    "* `1m` – 1 minute\n",
    "* `2m` – 2 minutes\n",
    "* `5m` – 5 minutes\n",
    "* `15m` – 15 minutes\n",
    "* `30m` – 30 minutes\n",
    "* `60m` – 60 minutes\n",
    "* `90m` – 90 minutes\n",
    "* `1h` – 1 hour\n",
    "\n",
    "#### Long-time trading (daily and others)\n",
    "* `1d` – 1 day\n",
    "* `5d` – 5 days\n",
    "* `1wk` – 1 week\n",
    "* `1mo` – 1 month\n",
    "* `3mo` – 3 months"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "602c0e08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State Space:  (10,)\n",
      "Action Space:  3\n"
     ]
    }
   ],
   "source": [
    "#instatiate the environment\n",
    "#HYP!\n",
    "env = TradingEnv(ticker=\"AAPL\", granularity=\"1d\", sliding_window=10, start_date=\"2021-01-01\", end_date=\"2025-01-01\", initial_cash=100000, initial_share=75)\n",
    "\n",
    "state_size = env.observation_space.shape\n",
    "action_size = env.action_space.n\n",
    "\n",
    "print('State Space: ', state_size)\n",
    "print('Action Space: ', action_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcd4f11b",
   "metadata": {},
   "source": [
    "### 4.2. Fundamental hypeparamenters to tweak <a ame=\"hyperparameters--4-2\"></a>\n",
    "\n",
    "* The `ticker` depends on the `yfinance` nomenclature.\n",
    "* The `granularity` hyperparameter as already mentioned is crucial, and depends on the type of trading the user wants to perform.\n",
    "* The `slidinig_window` should be approximately 10 days with a maximum of 20, but for the sake of computational efficiency we have decided to set it to 7 days (keep in mind that it also depends on the type of trading the user want to perform).\n",
    "* The `start_date` and `end_date` will generate the amount of data used for training in the period of interest, we must tweak them according to our purpose, but generally speaking they should cover a period of circa 5 years, in order to enclose possible financial market cycles.\n",
    "* The `initial_cash` and `initial_share` combined, represent the agent initial wallet value, and are of crucial importance for the learning of behaviour, **we must give to the agent a proper amount of stock and cash available at the beginning, otherwise it will learn degenerative policy.**\\\n",
    "**Note that the two amounts should depend on the market considered.**\n",
    "\n",
    "**NOTE** that a complete year of data (e.g.: `start_date='2020-01-01'` and `end_date='2021-01-01'`), with `granularity=\"1d\"`, contains approximately `253` prices, behave accordingly when you tweak fundamental hyperparameters, such as the batch size, episodes...\n",
    "\n",
    "**NOTE** since DQN is a value based approach, and since this Notebook could be implemented in many different cases, there are a lot of hyperparameters.\\\n",
    "To ease the user's coding, we allow the possibility to decline this notebook by tweaking them accordingly.\\\n",
    "Before every hyperparameter, in the code has been put a: `#HYP!`, so with a simple `Ctrl`+`f`, all hyperparameters can be found."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fef2928",
   "metadata": {},
   "source": [
    "### 4.3. Observation Space: Relative Price Variations <a name=\"observation_space--4-3\"></a>\n",
    "\n",
    "It is important to emphasize that the observation space is defined in terms of **percentage price variations** rather than **absolute price levels**.  \n",
    "This choice is fundamental from both a financial and a reinforcement learning perspective.\n",
    "\n",
    "Absolute prices are not directly comparable across assets or time periods: a price change of +1 has a very different meaning for an asset trading at 10 compared to one trading at 1,000. By using relative variations, the agent receives **scale-invariant information**, allowing it to learn patterns that are independent of nominal price levels.\n",
    "\n",
    "Moreover, financial markets are highly **non-stationary** in absolute terms, as prices tend to drift over time. Percentage variations, instead, exhibit more stable statistical properties, making them more suitable as inputs for learning algorithms and improving training stability.\n",
    "\n",
    "Finally, relative variations naturally align with the **economic objective of trading**, since profits and losses are inherently relative quantities. For these reasons, the observation space is constructed using relative price changes, enabling better generalization and a more meaningful learning process for the DQN agent.\n",
    "\n",
    "If you are interested, here is a similar project of mine where I needed stationarity in time series [Fast Fourier Transform in Finance](https://github.com/fraro01/Fourier-Transform-in-Finance)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb12368f",
   "metadata": {},
   "source": [
    "### What our agent is training on\n",
    "\n",
    "Show what we are analyzing, the time series of interest, note that we use as prices the closing prices given by `yfinance`. This behaviour can be changed by simpply tweaking the related hyperparameter from the `tradingenv.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "172d402a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#method of the TradingEnv class to show the data used for training\n",
    "env.show_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a1675fa",
   "metadata": {},
   "source": [
    "We fix the seed of the random number generator in order to reproduce the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "60d1d697",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set the seeds for reproducibility of results\n",
    "seed = 42 #HYP!\n",
    "\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "\n",
    "env.reset(seed=seed)\n",
    "env.action_space.seed(seed)\n",
    "env.observation_space.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f15a2d8e",
   "metadata": {},
   "source": [
    "If available on the current calculator, we take advantage of the **GPU** computational power"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be9689d2",
   "metadata": {},
   "source": [
    "**NOTE** make sure to have installed a `Pytorch` version capable of handling GPU computation! Otherwise the following code will not bring any computational improvement!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05ae1c41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# set the backend device to MPS or CUDA, if available\n",
    "if torch.cuda.is_available(): #prioritize CUDA since it is more powerful\n",
    "    device = torch.device(\"cuda\") #windows\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\") #mac\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "# print the used device\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6359dc7",
   "metadata": {},
   "source": [
    "## 5. Deep Q-Network Architecture <a name=\"DQN_architecture--5\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8321d462",
   "metadata": {},
   "source": [
    "### 5.1. Experience Replay Buffer <A name=\"E_R_B--5-1\"></a>\n",
    "\n",
    "Experience Replay Buffer, for the creation of semi-independent experiences to train the agent, in order to adress the first issue given by: *i.i.d*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c10fc748",
   "metadata": {},
   "source": [
    "Definition of the single array of experience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "99a973c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the structured dtype for an experience tuple, which will be stored in the replay memory\n",
    "experience_type = np.dtype([\n",
    "    ('state',      np.float32, state_size),   # current state, it must take the array of the observation space\n",
    "    ('action',     np.int8),                  # action taken, it is JUST THE action we took\n",
    "    ('reward',     np.float32),               # reward received\n",
    "    ('next_state', np.float32, state_size),   # next state\n",
    "    ('failure',    np.int8)                   # terminal flag (1 if done)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8fed524",
   "metadata": {},
   "source": [
    "Definition of the container of the arrays (replay buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e5c9f8b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the replay memory size hyperparameter\n",
    "#HYP!\n",
    "memory_size = 1000 #ADJUST IT ACCORDINGLY, (it was set to 100000 at the beginning)\n",
    "\n",
    "# Create the replay memory\n",
    "replay_memory = {\n",
    "    'size': memory_size,\n",
    "    'buffer': np.empty(shape=(memory_size,), dtype=experience_type),\n",
    "    'index': 0,\n",
    "    'entries': 0\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f99e758b",
   "metadata": {},
   "source": [
    "Function to store a new experience in the replay buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bc09691d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def store_experience(experience):\n",
    "    # store the experience in the buffer\n",
    "    replay_memory['buffer'][replay_memory['index']] = experience #we overwrite the experience at the current index, if the buffer is not full it will be empty, otherwise it will overwrite the oldest experience\n",
    "\n",
    "    # update the number of experiences in the buffer\n",
    "    replay_memory['entries'] = min(replay_memory['entries'] + 1, replay_memory['size']) # it cannot exceed the maximum size of the buffer\n",
    "\n",
    "    # update index, if the memory is full, start from the begging\n",
    "    replay_memory['index'] += 1\n",
    "    replay_memory['index'] = replay_memory['index'] % replay_memory['size'] #as long as 'index' is lower than 'size' it outputs 'index', then once they are equal it outputs 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9748a0f7",
   "metadata": {},
   "source": [
    "Function to sample a mini-batch of experiences from the replay buffer defined above.\\\n",
    "We will train the agent over these mini-batches.\n",
    "\n",
    "**IMPORTANT** since financial time series, cannot be modelled as a proper Markov Decision Process <small>[(see the Appendix at the end)](#Appendix--9-A)</small>, we cannot implement a uniform random sampling over the experience replay buffer, as for a typical DQN implementation, otherwise we mix different regimes losing the context.\\\n",
    "Instead, in this case we take the *sequential* last *`batch_size`-th* experiences collected, in order to preserve the context and temporal coherence, and we do that maintaining the circularity of our experience replay buffer, hence the `batch_size` hyperparameter, represents how much in the past history we go, in order to compute the backpropagation for the `online_network`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0a2ea0ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the batch size for sampling experiences\n",
    "#HYP!\n",
    "batch_size = 50 #hyperparameter to be tweaked, it represents how much in the past history we go for computing the backpropagation (it was 32 at the beginning)\n",
    "\n",
    "# function to sample a batch of experiences from the replay memory\n",
    "def sample_experiences():\n",
    "\n",
    "    \"\"\" IMPOMRTANT, SEE THE NOTES WRITTEN ABOVE\n",
    "    # select uniformly at random a batch of experiences from the memory\n",
    "    idxs = np.random.choice(range(replay_memory['entries']), batch_size, replace=False) #without replacement, we want unique experiences in the batch, if 'entries' is lower than 'batch_size' it will raise an error, but in that case we should not sample a batch of experiences, we should wait until we have enough experiences in the buffer\n",
    "    # return the batch of experiences\n",
    "    experiences = replay_memory['buffer'][idxs]\n",
    "    \"\"\"\n",
    "\n",
    "    #in case we are not circular\n",
    "    #experiences = replay_memory['buffer'][:replay_memory['entries']][-batch_size:]\n",
    "\n",
    "    # --- take the last `batch_size` sequential experiences (chronological order) ---\n",
    "    entries = replay_memory['entries']\n",
    "    size = replay_memory['size']\n",
    "    if entries < batch_size:\n",
    "        raise ValueError(f\"Not enough entries in replay memory to sample {batch_size} items (have {entries}).\")\n",
    "\n",
    "    # 'index' points to the next insertion position, so last inserted element is at index-1 (mod size)\n",
    "    end = (replay_memory['index'] - 1) % size\n",
    "    start = (replay_memory['index'] - batch_size) % size\n",
    "\n",
    "    if start <= end:\n",
    "        idxs = np.arange(start, end + 1)\n",
    "    else:\n",
    "        # wrap-around: take slice from start..size-1 then 0..end\n",
    "        idxs = np.concatenate((np.arange(start, size), np.arange(0, end + 1)))\n",
    "\n",
    "    # ensure idxs length == batch_size\n",
    "    assert len(idxs) == batch_size\n",
    "\n",
    "    # preserve chronological order: older -> newer\n",
    "    experiences = replay_memory['buffer'][idxs]\n",
    "\n",
    "    return experiences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0fdbeee",
   "metadata": {},
   "source": [
    "### 5.2. Neural Network Architecture <a name=\"NN_Architecture--5-2\"></a>\n",
    "\n",
    "Since we are dealing with a continuous environment (continuous price variations), we are not in the field of tabular data, hence we need a function approximator for the value functions, this is the reason why we end up with the Neural Network Architecture for the $Q$ function.\\\n",
    "See the concept of the [Density of $\\mathbb{Q}$ in $\\mathbb{R}$](https://math.stackexchange.com/questions/103839/proof-that-mathbbq-is-dense-in-mathbbr)\n",
    "\n",
    "It will output the $Q(s,a)$ for all possible *actions* in the given state $s$, after the observation taken as input.\\\n",
    "Here many hyperparameters could be tweaked, such as the hidden layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fed8465a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hyperparameters for the neural network architecture to be tweaked\n",
    "#HYP!\n",
    "first_hidden_layer= 128\n",
    "second_hidden_layer= 64\n",
    "\n",
    "def create_network():\n",
    "\n",
    "      # Define a deep neural network using Sequential:\n",
    "      # Each layer feeds directly into the next one.\n",
    "      dnn = torch.nn.Sequential( \n",
    "            # First fully connected layer maps state inputs to 512 hidden units\n",
    "            torch.nn.Linear(state_size[0], first_hidden_layer),\n",
    "            \n",
    "            # ReLU activation introduces nonlinearity\n",
    "            torch.nn.ReLU(),\n",
    "            \n",
    "            # Second fully connected layer (hidden layer with 128 units)\n",
    "            torch.nn.Linear(first_hidden_layer, second_hidden_layer),\n",
    "            \n",
    "            # Another ReLU activation\n",
    "            torch.nn.ReLU(),\n",
    "            \n",
    "            # Output layer: one unit per possible action\n",
    "            # Produces Q-values\n",
    "            torch.nn.Linear(second_hidden_layer, action_size)\n",
    "      )\n",
    "    \n",
    "      # Return the constructed model\n",
    "      return dnn.to(device) #the model goes to the chosen device (GPU or CPU)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67396881",
   "metadata": {},
   "source": [
    "Creation of two separated networks (in terms of weights, since they are created from the same exact acrhitecture), in order to adress the second issue in *i.i.d.*, of *identically distributed* targets.\n",
    "\n",
    "$\\displaystyle L(\\theta) = E_{(s,a) \\sim U(D)} \\left[ ( r + \\gamma \\underset{a}{\\text{ max }} Q(s',a;\\theta^{-}) - Q(s,a;\\theta))^2 \\right]$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fc3fee53",
   "metadata": {},
   "outputs": [],
   "source": [
    "#we need two separates network for the proper backpropagation defined in DQN\n",
    "online_q = create_network() # online q-network for the prediction\n",
    "target_q = create_network() # target network for the Ground-Truth Q-value estimation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5d78cfe",
   "metadata": {},
   "source": [
    "Optimizer only for the online network, since is the only one to be trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3526b17a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#the variable \"optimizer\" will be used below by the \"optimizie()\" function, in order to only backpropagate the gradients on the online_q parameters, while the target_q parameters will be updated only when we call the \"update_target\" function, which copies the online_q parameters to the target_q parameters\n",
    "#HYP!\n",
    "learning_rate = 0.004 #(at the beginning it was 0.007)\n",
    "optimizer = torch.optim.RMSprop(online_q.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55b1f37e",
   "metadata": {},
   "source": [
    "The target network is not trained, but sometimes we need to **update its weights to match the online network weights**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "31b9b295",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_target():\n",
    "    # copy the parameters from the online model to the target model\n",
    "    for target, online in zip(target_q.parameters(), online_q.parameters()):\n",
    "        target.data.copy_(online.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b236ff10",
   "metadata": {},
   "source": [
    "Optimizer, for computing the loss and the backpropagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87704058",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the discount factor\n",
    "#HYP!\n",
    "gamma = 0.95 #(at the beginning it was 0.99)\n",
    "\n",
    "def optimize():\n",
    "\n",
    "    # sample a batch of experiences from the replay buffer, as mentioned in the last cell of section 5.1.\n",
    "    batch = sample_experiences()\n",
    "    \n",
    "    # prepare the experience as tensors, take 'em all from the whole batch\n",
    "    states      = torch.from_numpy(batch['state'].copy()).float().to(device) #we transfer all of them to the chosen device (GPU or CPU)\n",
    "    actions     = torch.from_numpy(batch['action'].copy()).long().to(device)\n",
    "    rewards     = torch.from_numpy(batch['reward'].copy()).float().to(device) \n",
    "    next_states = torch.from_numpy(batch['next_state'].copy()).float().to(device)\n",
    "    failures    = torch.from_numpy(batch['failure'].copy()).float().to(device)\n",
    "\n",
    "    # get the values of the Q-function at next state from the \"target\" network \n",
    "    # remember to detach, we need to treat these values as constants \n",
    "    q_target_next = target_q(next_states).detach() #treat the tensor as a constant, do not calculate the gradient with respect to it\n",
    "    \n",
    "    # get the max value \n",
    "    max_q_target_next = q_target_next.max(1)[0]\n",
    "\n",
    "    # one important step, often overlooked, is to ensure \n",
    "    # that failure states are grounded to zero\n",
    "    max_q_target_next *= (1 - failures.float())\n",
    "\n",
    "    # calculate the target \n",
    "    target = rewards + gamma * max_q_target_next\n",
    "\n",
    "    # finally, we get the current estimate of Q(s,a)\n",
    "    # here we query the current \"online\" network\n",
    "    q_online_current = torch.gather(online_q(states), 1, actions.unsqueeze(1)).squeeze(1)\n",
    "\n",
    "    # create the errors\n",
    "    td_error = target - q_online_current\n",
    "\n",
    "    # calculate the loss\n",
    "    loss = td_error.pow(2).mean()\n",
    "\n",
    "    # backward pass: compute the gradients\n",
    "    optimizer.zero_grad() #set to zero the gradients of the parameters, otherwise they would be accumulated across optimization steps\n",
    "    loss.backward() #backpropagation based on the \"loss\" variable\n",
    "\n",
    "    # update model parameters\n",
    "    #NOTICE thta optimizer is a defined variable (see cells above) on the online_q parameters, so it will update those parameters based on the computed gradients, while the target_q parameters will remain unchanged until we call the \"update_target\" function\n",
    "    optimizer.step() #update the parameters of the online model based on the computed gradients"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "563835c2",
   "metadata": {},
   "source": [
    "### 5.3. Exploration Vs Exploitation <a name=\"Exploration_vs_Exploitation--5-3\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "347c5115",
   "metadata": {},
   "source": [
    "Hyperparameters to be set for the exploration straetegies. *($\\epsilon$ decay)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "39038a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "#HYP!\n",
    "# define decay parameters (max, min, steps)\n",
    "#uncomment the following two lines, if you want to use the normalization or scaling of epsilons, otherwise you can tweak the hyperparameters in the logspace generation of epsilons to get the desired range without needing to scale them\n",
    "#epsilon_max = 1.0\n",
    "#epsilon_min = 0.01\n",
    "epsilon_decay_steps = 7500 #(it was set to 10000 at the beginning), adjust it according to your environment.\n",
    "\n",
    "# generate epsilons\n",
    "epsilons = np.logspace(start=0, stop=-2, num=epsilon_decay_steps, base=10)\n",
    "\n",
    "#simplest method to change values of epsilons\n",
    "epsilons = epsilons**0.5 #powers < 1, emphasize greater values => more exploration! balance this hyperparameter!\n",
    "\n",
    "#THE FOLLOWING ARE TWO ALTERNATIVE WAYS TO SCALE THE EPSILONS TO THE DESIRED RANGE, YOU CAN CHOOSE ONE OF THEM, OR TWEAK THE HYPERPARAMETER IN THE LOGSPACE GENERATION OF EPSILONS TO GET THE DESIRED RANGE WITHOUT NEEDING TO SCALE THEM\n",
    "\n",
    "# normalize epsilons \n",
    "# epsilons = (epsilons - epsilon_min) / (epsilon_max - epsilon_min)\n",
    "    \n",
    "# scale  epsilons to the desired range\n",
    "# epsilons = (epsilon_max - epsilon_min) * epsilons + epsilon_min"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69c384cb",
   "metadata": {},
   "source": [
    "Chosen exploration strategy.\\\n",
    "Based on the picked $\\epsilon$, we alternate a random action selection and the greedy selection (greedy based on the value of the $Q(s,a,\\theta)$ returned by our neural network)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f28f0a2",
   "metadata": {},
   "source": [
    "`random_pi()` is the baseline random policy, to be used as reference, in order to understand whether we are actually learning smoething"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5add7b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_pi(state):\n",
    "    # selects an action uniformly at random\n",
    "    # from the environment's action space.\n",
    "    return env.action_space.sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a25acb4a",
   "metadata": {},
   "source": [
    "At the end of training the online network will be used to implement the policy.\\\n",
    "`dqn_policy()` it simply acts greedy given the input state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "433ca563",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dqn_pi(state):\n",
    "    # convert the state into a tensor\n",
    "    state = torch.as_tensor(state, dtype=torch.float32).to(device) #TODO! CHECK IT!\n",
    "\n",
    "    # compute Q-values from the network\n",
    "    #since Python/Numpy is not able to read tensors in the GPU, in general if we need values outside training\n",
    "    #we need to transfer them from the GPU to the CPU, but keep in mind that the transfer is computationally intense!\n",
    "    q_values = online_q(state).detach().cpu().numpy().squeeze() #TODO! CHECK IT!\n",
    "\n",
    "    # select greedy action\n",
    "    action = int(np.argmax(q_values)) \n",
    "\n",
    "    # return the action\n",
    "    return action"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8b5ff48",
   "metadata": {},
   "source": [
    "`epsilon_greedy()` combines `random_pi()` and `dqn_pi()` in order to be indeed $\\epsilon$-greedy decaying"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ae9794a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def epsilon_greedy(state, step):\n",
    "    epsilon_min = 0.1 #the last value to keep taking, once we have finished al the decayed array\n",
    "    # get the epsilon value    \n",
    "    epsilon = epsilons[step] if step < epsilon_decay_steps else epsilon_min\n",
    "\n",
    "    # Exploration\n",
    "    if random.random() < epsilon:\n",
    "        action = random_pi(state)\n",
    "\n",
    "    # Exploitation\n",
    "    else:\n",
    "        action = dqn_pi(state)\n",
    "    \n",
    "    return action"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8121af31",
   "metadata": {},
   "source": [
    "### 5.4. Policy Evaluation <a name=\"Policy_Evaluation--5-4\"></a>\n",
    "\n",
    "Function to evaluate a policy, it returns the average reward obtained over a number of episodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3ca2dffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(pi, episodes=1):\n",
    "\n",
    "    # collect total rewards per episode\n",
    "    rewards = []\n",
    "    actions = [] #used only if the episodes==1\n",
    "\n",
    "    # loop over episodes\n",
    "    for episode in range(episodes):\n",
    "\n",
    "        # reset the environment\n",
    "        state, _ = env.reset()\n",
    "        done = False\n",
    "        total_reward = 0.0\n",
    "\n",
    "        # run an episode\n",
    "        while not done:\n",
    "            action = pi(state)\n",
    "            state, reward, terminal, truncated, _ = env.step(action)\n",
    "            total_reward += reward\n",
    "            done = terminal or truncated\n",
    "            \n",
    "            #if we only run one episode, we could be interested in the types of actions taken\n",
    "            if episodes == 1:\n",
    "                actions.append(action)\n",
    "\n",
    "        # store the total reward    \n",
    "        rewards.append(total_reward)\n",
    "            \n",
    "    # return the average reward over the episodes, and if we only run one episode, also return the types of actions taken in that episode      \n",
    "    return np.mean(rewards), actions "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a38c3170",
   "metadata": {},
   "source": [
    "## 6. Putting things together, Deep Q-Network Algorithm <a name=\"Putting_things_together--6\"></a>\n",
    "Putting all the things together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "62f5d446",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dqn(memory_start_size, target_update_steps, max_episodes):\n",
    "    \n",
    "    # create a score tracker for statistic purposes\n",
    "    scores = []\n",
    "    \n",
    "    # counter for the number of steps \n",
    "    step = 0\n",
    "\n",
    "    # update the target model with the online one, before even starting, so to allign the two NNs\n",
    "    update_target()\n",
    "                   \n",
    "    # train until the maximum number of episodes\n",
    "    for episode in range(max_episodes):\n",
    "        \n",
    "        # reset the environment before starting the episode\n",
    "        state, _ = env.reset()\n",
    "        done = False\n",
    "\n",
    "        # interact with the environment until the episode is done\n",
    "        while not done:\n",
    "                    \n",
    "            # select the action using the exploration policy\n",
    "            action = epsilon_greedy(state, step)\n",
    "\n",
    "            # perform the selected action\n",
    "            next_state, reward, terminal, truncated, _ = env.step(action)\n",
    "            done = terminal or truncated\n",
    "            failure = terminal and not truncated\n",
    "\n",
    "            # store the experience into the replay buffer\n",
    "            experience = (state, action, reward, next_state, failure)\n",
    "            store_experience(experience)\n",
    "    \n",
    "            # optimize the online model ONLY AFTER the replay buffer is large enough\n",
    "            if replay_memory['entries'] > memory_start_size:\n",
    "                optimize()\n",
    "                 \n",
    "                # sometimes, synchronize the target model with the online model\n",
    "                if step % target_update_steps == 0:\n",
    "                    update_target()\n",
    "                \n",
    "            # update current state to next state\n",
    "            state = next_state\n",
    "\n",
    "            # update the step counter\n",
    "            step += 1\n",
    "\n",
    "        # After each episode, evaluate the policy\n",
    "        score = evaluate(dqn_pi, episodes=10)[0]\n",
    "\n",
    "        # store the score in the tracker\n",
    "        scores.append(score)\n",
    "\n",
    "        # print some informative logging for each episode!\n",
    "        message = 'Episode {:03}, score {:05.1f}'\n",
    "        message = message.format(episode+1, score)\n",
    "        print(message, end='\\r', flush=True)\n",
    "        \n",
    "    return scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cd9c2f2",
   "metadata": {},
   "source": [
    "Apply the DQN to our `TradingEnv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32c240f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fraro\\AppData\\Local\\Temp\\ipykernel_21668\\3259473271.py:3: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  replay_memory['buffer'][replay_memory['index']] = experience #we overwrite the experience at the current index, if the buffer is not full it will be empty, otherwise it will overwrite the oldest experience\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 202, score 74864.3\r"
     ]
    }
   ],
   "source": [
    "#HYP!\n",
    "# set the hyperparameters\n",
    "memory_start_size = 88 #ADJUST IT ACCORDINGLY IT IS CRUCIAL, (it was set to 1000 at the beginning), it is the number of experiences we need to have in the replay buffer before starting the optimization of the online model, it should be at least equal to the batch size, but it can be higher, if we want to have more diverse experiences in the buffer before starting to optimize the model\n",
    "target_update_steps = 10 #steps between two updates of the target network, (it was set to 10 at the beginning), it is a crucial hyperparameter to be tweaked, if it is too low, the target network will be updated too often and it will not provide a stable target for the online network, if it is too high, the target network will be updated too rarely and it will not track the online network enough, so we need to find a good balance\n",
    "max_episodes = 300 #ADJUST IT ACCORDINGLY (at least 200 at least!, but we aim 1000)\n",
    "\n",
    "#run the algorithm\n",
    "dqn(memory_start_size, target_update_steps, max_episodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3706bff6",
   "metadata": {},
   "source": [
    "### 6.1. Compare *DQN* to *random_pi* <a name=\"compare--6-1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbda097f",
   "metadata": {},
   "source": [
    "Experiment to understand how dqn is learning over the episodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0fc21c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def experiment(max_episodes):\n",
    "\n",
    "    global online_q, target_q, optimizer, replay_memory, epsilons\n",
    "\n",
    "    #HYP!\n",
    "    # List of random seeds to test algorithm stability\n",
    "    seeds = (12, 34, 56, 78, 90)\n",
    "\n",
    "    # Container to collect all experiment results\n",
    "    results = []\n",
    "\n",
    "    # Run an independent training experiment per seed\n",
    "    for seed in seeds:\n",
    "\n",
    "        print(\"Experiment seed: \", seed)\n",
    "\n",
    "        # Set all relevant random seeds for reproducibility\n",
    "        #NOTE THAT FOR EACH EPISODE WE INITIALIZE EVERYTHING FROM SCRATCH, SO WE NEED TO SET THE SEEDS FOR EACH EPISODE\n",
    "        torch.manual_seed(seed)\n",
    "        np.random.seed(seed)\n",
    "        random.seed(seed)\n",
    "\n",
    "        # reset the environment\n",
    "        env.reset(seed=seed)\n",
    "        env.action_space.seed(seed)\n",
    "        env.observation_space.seed(seed)\n",
    "\n",
    "        # create online and target models\n",
    "        online_q = create_network()\n",
    "        target_q = create_network()\n",
    "        optimizer = torch.optim.RMSprop(online_q.parameters(), lr=learning_rate)\n",
    "\n",
    "        # create the replay memory\n",
    "        replay_memory = {\n",
    "            'size': memory_size,\n",
    "            'buffer': np.empty(shape=(memory_size,), dtype=experience_type),\n",
    "            'index': 0,\n",
    "            'entries': 0\n",
    "        }\n",
    "\n",
    "        # create the epsilon values from scratch\n",
    "        #HYP!\n",
    "        epsilons = np.logspace(start=0, stop=-2, num=epsilon_decay_steps, base=10)\n",
    "        #epsilons = (epsilons - epsilon_min) / (epsilon_max - epsilon_min)\n",
    "        #epsilons = (epsilon_max - epsilon_min) * epsilons + epsilon_min\n",
    "        epsilons = epsilons**0.5 #hyperparamet to tune!\n",
    "\n",
    "        # train the network    \n",
    "        scores = dqn(memory_start_size, target_update_steps, max_episodes)\n",
    "        \n",
    "        # smooth the result using a sliding window convolution (moving average)\n",
    "        #HYP!\n",
    "        sliding_windows = 25\n",
    "        scores = np.convolve(scores, np.ones(sliding_windows)/sliding_windows, mode='valid')\n",
    "                \n",
    "        # collect the results\n",
    "        results.append(scores)\n",
    "\n",
    "        print(\"\")\n",
    "\n",
    "    # calculate max, min and average scores among experiments\n",
    "    max_score = np.max(results, axis=0).T #take the maximum score over the seed dimension per each episode!, keep the episode separated, (T is the transposed, but for 1D array is the same! useless here)\n",
    "    min_score = np.min(results, axis=0).T\n",
    "    mean_score = np.mean(results, axis=0).T\n",
    "\n",
    "    # prepare the results\n",
    "    experiment_results = {\n",
    "        'max_score': max_score,\n",
    "        'min_score': min_score,\n",
    "        'mean_score': mean_score\n",
    "    }\n",
    "    \n",
    "    return experiment_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ce91ef7",
   "metadata": {},
   "source": [
    "Run of the experiment on our environemnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb04ab0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#HYP!\n",
    "# Define the experiment setup and hyperparameters\n",
    "gamma = 0.95               # discount factor (at the beginning it was 0.99)\n",
    "learning_rate = 0.004      # step size for the optimizer\n",
    "batch_size = 50          # it was set to 512! number of experiences per batch\n",
    "first_hidden_layer = 128   # size of the first hidden layer\n",
    "second_hidden_layer = 64  # size of the second hidden layer\n",
    "\n",
    "# Run the experiment\n",
    "#HYP!\n",
    "dqn_results = experiment(max_episodes=1500) #it was set at 1500 at the beginning, adjust it according to your environment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dc00480",
   "metadata": {},
   "source": [
    "Experiment to see the performance of a random behaviour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cfcbec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def experiment_random(max_episodes):\n",
    "\n",
    "    #HYP!\n",
    "    # List of random seeds to test algorithm stability\n",
    "    seeds = (12, 34, 56, 78, 90)\n",
    "\n",
    "    # Container to collect all experiment results\n",
    "    results = []\n",
    "\n",
    "    # Run an independent training experiment per seed\n",
    "    for seed in seeds:\n",
    "\n",
    "        print(\"Experiment seed: \", seed)\n",
    "\n",
    "         # Set all relevant random seeds for reproducibility\n",
    "        np.random.seed(seed)\n",
    "        random.seed(seed)\n",
    "\n",
    "        # reset the environment\n",
    "        env.reset(seed=seed)\n",
    "        env.action_space.seed(seed)\n",
    "        env.observation_space.seed(seed)\n",
    "\n",
    "        # train the network\n",
    "        #HYP!\n",
    "        scores = [evaluate(random_pi, episodes=33)[0] for _ in range(max_episodes)]\n",
    "            \n",
    "        # smooth the result using a sliding window convolution (moving average)\n",
    "        #HYP!\n",
    "        sliding_windows = 25\n",
    "        scores = np.convolve(scores, np.ones(sliding_windows)/sliding_windows, mode='valid')\n",
    "                \n",
    "        # collect the results\n",
    "        results.append(scores)\n",
    "\n",
    "        print(\"\")\n",
    "\n",
    "    # calculate max, min and average scores among experiments\n",
    "    max_score = np.max(results, axis=0).T\n",
    "    min_score = np.min(results, axis=0).T\n",
    "    mean_score = np.mean(results, axis=0).T\n",
    "\n",
    "    # prepare the results\n",
    "    experiment_results = {\n",
    "        'max_score': max_score,\n",
    "        'min_score': min_score,\n",
    "        'mean_score': mean_score\n",
    "    }\n",
    "\n",
    "    \n",
    "    return experiment_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f449c92",
   "metadata": {},
   "source": [
    "Run the experiment for the randomic behaviour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fd5e912",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_pi_results = experiment_random(max_episodes=1500) #it was set at 1500 at the beginning. insert the same number inserted above for the \"dqn_results\" experiment, so to have the same length to plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27c814b3",
   "metadata": {},
   "source": [
    "### Comparison between DQN and random_pi in learning in terms of robustness with confidence bands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d1cd4fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define the plots\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.title('DQN vs Random Policy')\n",
    "plt.ylabel('Average reward per episode [$]')\n",
    "plt.xlabel('Episodes')\n",
    "\n",
    "#get the results of the 2 experiments\n",
    "dqn_episodes = range(len(dqn_results['max_score']))\n",
    "random_pi_episodes = range(len(random_pi_results['max_score']))\n",
    "\n",
    "plt.plot(random_pi_results['max_score'], 'b', linewidth=1, label=\"random_pi\")\n",
    "plt.plot(random_pi_results['min_score'], 'b', linewidth=1)\n",
    "plt.plot(random_pi_results['mean_score'], 'b', linewidth=2)\n",
    "plt.fill_between(random_pi_episodes, random_pi_results['min_score'], random_pi_results['max_score'], facecolor='b', alpha=0.3)\n",
    "\n",
    "plt.plot(dqn_results['max_score'], 'y', linewidth=1, label=\"DQN\")\n",
    "plt.plot(dqn_results['min_score'], 'y', linewidth=1)\n",
    "plt.plot(dqn_results['mean_score'], 'y', linewidth=2)\n",
    "plt.fill_between(dqn_episodes, dqn_results['min_score'], dqn_results['max_score'], facecolor='y', alpha=0.3)\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92d43945",
   "metadata": {},
   "source": [
    "## 7. What our agent is capable of in reality <a name=\"capabilities--7\"></a>\n",
    "\n",
    "It is crucial to clarify a fundamental aspect of reinforcement learning applied to financial trading, we are somehow *in the middle of reinforcement learning and supervised learning problem*.\\\n",
    "While the problem is formally framed as a reinforcement learning task, it exhibits several characteristics that make it closer to an offline and supervised-like learning setting, as in between a problem of pattern recognition.\n",
    "\n",
    "In particular, the actions taken by the agent do not influence the environment dynamics: the price time series is pre-generated and entirely exogenous. As a consequence, the environment is non-reactive, and the agent interacts with a fixed historical trajectory rather than a fully interactive Markov Decision Process. <small>[(see the Appendix on the Markovian assumptions)](#Appendix--9-A)</small>\\\n",
    "[See the fiancial market whale](https://fenefx.com/en/blog/what-is-a-financial-market-whale/)\n",
    "\n",
    "This property introduces a significant risk of overfitting. Evaluating the cumulative reward obtained by the agent on the same time series used during training does not provide meaningful information about its true generalization capability. In such a setting, the agent may simply learn spurious correlations or regime-specific patterns present in the training data, achieving high in-sample performance without learning a robust trading strategy.\n",
    "\n",
    "Therefore, performance evaluation must be conducted on strictly unseen time series, either from future time periods or from different assets, in order to assess the agent’s ability to generalize to a real and previously unobserved market environment. Only out-of-sample evaluation can provide a realistic estimate of the strategy’s effectiveness and risk profile."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa9ccb14",
   "metadata": {},
   "source": [
    "Thus, we will evaluate the performance of our agent over a shifted and shorter environment, **over the same market**, this last thing it is fundamental again.\\\n",
    "We should test our policy on the same market over which it has been trained on, because different markets might have different types of characteristics, such as: market cap, amount of investors, regulatory rules, volatility..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7dec705",
   "metadata": {},
   "outputs": [],
   "source": [
    "#instantiate a new environment, we will use it for testing the trained policy\n",
    "#choose a shorter start_date - end_date range to speed up the evaluation phase\n",
    "#HYP!\n",
    "env = TradingEnv(ticker=\"AAPL\", granularity=\"1d\", sliding_window=10, start_date=\"2025-01-01\", end_date=\"2026-01-01\", initial_cash=100000, initial_share=75)\n",
    "\n",
    "state_size = env.observation_space.shape\n",
    "action_size = env.action_space.n\n",
    "\n",
    "print('State Space: ', state_size)\n",
    "print('Action Space: ', action_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23aa618a",
   "metadata": {},
   "source": [
    "It is important, to note that all financial time series show a drift, that even on short terms if strongly present, could induce a random policy to obtain successful cumulative reward.\\\n",
    "**In any case, the trained policy should always be higher than the random one, even if slightly higher, it means the agent at least has learnt something from the hidden patterns of the time series.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cbc9b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#method of the TradingEnv class to show the data used testing the trained policy\n",
    "env.show_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a35cd8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#just for comparison test the perfomance of the random policy\n",
    "evaluate(random_pi, episodes=1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "057ec467",
   "metadata": {},
   "outputs": [],
   "source": [
    "#NOTE THAT IT WILL ANSWER ON THE BASIS OF THE LAST \"online_q\" TRAINED!\n",
    "#we can even run it many times with many different input settings to draw a Design of Experiments curve\n",
    "cumulative_reward, actions_taken = evaluate(dqn_pi, episodes=1)\n",
    "\n",
    "env.show_data_with_actions(actions_taken) #the actions we took\n",
    "cumulative_reward #the related return"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69d911f9",
   "metadata": {},
   "source": [
    "## 8. Conclusions, Limitations and Future Improvements <a name=\"Conclusions--8\"></a>\n",
    "\n",
    "The results highlight a difference between a **random policy** and the policy learned by the DQN agent.  \n",
    "This suggests that the agent is able to capture **non-trivial patterns** in market dynamics, potentially exploiting regularities that go beyond pure randomness. However, these results should be interpreted with caution, as financial markets are complex and highly noisy systems.\n",
    "\n",
    "It is well known in the financial literature that markets may exhibit recurring structures <small>[(see again FFT in Finance)](https://github.com/fraro01/Fourier-Transform-in-Finance)</small>, such as [CandleStick patterns](https://en.wikipedia.org/wiki/Candlestick_pattern); which reflect collective trader behavior and market psychology. Reinforcement learning methods may implicitly learn such patterns without explicitly encoding them, like in pattern recognition.\\\n",
    "In this sense we have built an adaptive system capable of performing pattern recongition, that could be actually used for many other cases in many other environments!\n",
    "\n",
    "### Limitations\n",
    "\n",
    "Despite the encouraging results, the proposed model suffers from several limitations:\n",
    "\n",
    "- **Strong assumptions on the action space**:  \n",
    "  The agent can only buy, sell, or hold a single unit of the asset at each step. This is a restrictive assumption that does not reflect real trading behavior.\n",
    "\n",
    "- **Simplified state representation**:  \n",
    "  The observation space is limited to a fixed-size sliding window of past price variations, excluding other potentially informative features such as volume, volatility indicators, or macroeconomic signals.\n",
    "\n",
    "- **Sensitivity to hyperparameters**:  \n",
    "  The performance of the model strongly depends on the choice of neural network architecture and DQN hyperparameters, which have not been exhaustively optimized.\\\n",
    "  Furthermore even the environment is strongly dependent on hyperparamters, that should be properly defined by a deep financial knowledge.\\\n",
    "  Even the initialization of the cash and share hyperparameters is crucial, because from this, the agent could learn degenerative behaviours.\n",
    "\n",
    "- **Limited time horizon and computational constraints**:  \n",
    "  Computational power limits the amount of historical data and the length of training, potentially preventing the agent from learning properly.\n",
    "\n",
    "### Future Improvements\n",
    "\n",
    "Several directions can be explored to improve the model (many of them can be achieved by manipulating the script `tradingenv.py`):\n",
    "\n",
    "- **Richer action space**:  \n",
    "  Allow the agent to buy or sell multiple units per action, enabling position sizing and more realistic portfolio management.\\\n",
    "  For the sake of reality, we should even introduce, transaction fees.\n",
    "\n",
    "- **Expanded state space**:  \n",
    "  Incorporate additional features such as technical indicators, trading volume, volatility measures, or external signals.\n",
    "\n",
    "- **Hyperparameters optimization**:  \n",
    "  Perform a systematic search (e.g. grid search or random search) over network architectures and learning parameters.\\\n",
    "  Especially for time resolution, to extend the framework to different time scales, such as intraday or hourly trading, to analyze high-frequency dynamics.\n",
    "\n",
    "- **Use of finer models**:  \n",
    "  We could try to use different models, such as DDQN, Rainbow or even policy-based methods.\\\n",
    "  Even for the sampling of the experience replay buffer we could implement finer models, such as: Prioritized Experience Replay, stratified/temporal-aware, but always keeping in mind that we need to preserve the context in our samples!\n",
    "\n",
    "  A very interesting path to follow would be the construction of a \"filtering pipeline\", with the application of a Fast Fourier Transform at the beginning [FFT in Finance](https://github.com/fraro01/Fourier-Transform-in-Finance) that filters the unwanted noise of the price variations (set the percentage threshold), and then the application of the DQN RL algorithm once the prices are \"cleaned\".\n",
    "\n",
    "- **Real-world deployment**:  \n",
    "  After proper validation and risk management, the trained agent could be connected to a trading bot interfaced with a real trading wallet.\n",
    "\n",
    "\n",
    "Overall, while the results are promising, further experimentation and validation are required before considering real-world applications."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbe97a32",
   "metadata": {},
   "source": [
    "## 9. Appendix <a name=\"Appendix--9\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38ae860d",
   "metadata": {},
   "source": [
    "### 9.A. On the Markov Decision Process formulation in financial trading <a name=\"Apendix--9-A\"></a>\n",
    "\n",
    "A Markov Decision Process (MDP) is defined by a tuple $(\\mathcal{S}, \\mathcal{A}, P, R, \\gamma)$, where the transition function $P(s_{t+1} \\mid s_t, a_t)$ explicitly depends on the action taken by the agent.\\\n",
    "This dependency implies that actions actively shape the future evolution of the environment.\n",
    "\n",
    "In the context of financial trading on historical price data, this assumption does not strictly hold.\\\n",
    "The price time series is pre-generated and **entirely exogenous**, meaning that *the agent’s actions do not influence the future market states.*\n",
    "As a consequence, the state transition dynamics satisfy:\n",
    "\n",
    "$P(s_{t+1} \\mid s_t, a_t) = P(s_{t+1} \\mid s_t)$\n",
    "\n",
    "The agent’s actions affect only the reward function, through realized profits and losses, while the environment evolution remains unchanged.\\\n",
    "This results in a non-reactive environment, where the agent interacts with a fixed historical trajectory rather than a fully interactive MDP.\n",
    "\n",
    "Therefore, the trading problem is more accurately described as an offline reinforcement learning problem with exogenous dynamics, or as a degenerate MDP.\\\n",
    "This formulation highlights the increased risk of overfitting and the necessity of strict out-of-sample evaluation, as the agent may otherwise exploit idiosyncratic patterns specific to the training data rather than learning a robust trading policy.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
